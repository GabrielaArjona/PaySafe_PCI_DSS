{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ff037",
   "metadata": {},
   "source": [
    "# B) PCI Controls and Audit checks\n",
    "\n",
    "PCI basic checks for SafePay project\n",
    "\n",
    "- Confirm PAN is not stored in repo artifacts.\n",
    "- Confirm tokenization outputs exist and tokens are unique.\n",
    "- Confirm baseline policy artifact exists.\n",
    "- Produce basic evidences for audit consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Project\\SafePay\\02_Framework\\pci_baseline.json\n",
      "C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\\outputs\\tokenized_payments.csv\n",
      "C:\\Project\\SafePay\\01_Case\\B_PCI_Controls_and_Audit\\outputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re, csv, json\n",
    "import datetime, hashlib\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path('..').resolve()\n",
    "output_path = Path(\"../outputs\").resolve()\n",
    "token_path = Path(\"../../A_Payment_Dataflow/outputs/tokenized_payments.csv\").resolve()\n",
    "pci_baseline = Path(\"../../../02_Framework/pci_baseline.json\").resolve()\n",
    "\n",
    "print(output_path)\n",
    "print(token_path)\n",
    "print(pci_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a14b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done\n"
     ]
    }
   ],
   "source": [
    "checks = []  \n",
    "\n",
    "# 1) validate\n",
    "if token_path.exists():\n",
    "    checks.append((\"CHK-001\",\"tokenized_file_present\",\"PASS\", str(token_path)))\n",
    "else:\n",
    "    checks.append((\"CHK-001\",\"tokenized_file_present\",\"FAIL\",\"tokenized file not found\"))\n",
    "\n",
    "if baseline_path.exists():\n",
    "    checks.append((\"CHK-002\",\"baseline_present\",\"PASS\", str(baseline_path)))\n",
    "else:\n",
    "    checks.append((\"CHK-002\",\"baseline_present\",\"FAIL\",\"pci_baseline.json not found\"))\n",
    "\n",
    "# 2) validate tokens\n",
    "pan_pattern = re.compile(r\"\\b\\d{13,19}\\b\")  # PAN pattern\n",
    "if token_path.exists():\n",
    "    try:\n",
    "        df = pd.read_csv(token_path, dtype=str, keep_default_na=False)\n",
    "\n",
    "        # a) PAN leak check\n",
    "        pan_cols = [col for col in df.columns if df[col].astype(str).str.contains(pan_pattern).any()]\n",
    "        if pan_cols:\n",
    "            checks.append((\"CHK-003\",\"pan_leak_check\",\"FAIL\", f\"PAN-like sequences found in columns: {pan_cols}\"))\n",
    "        else:\n",
    "            checks.append((\"CHK-003\",\"pan_leak_check\",\"PASS\",\"No PAN-like sequences found\"))\n",
    "\n",
    "        # b) Token uniqueness\n",
    "        if 'token' in df.columns:\n",
    "            total = len(df)\n",
    "            unique = df['token'].nunique()\n",
    "            if total == unique:\n",
    "                checks.append((\"CHK-004\",\"token_uniqueness\",\"PASS\", f\"total={total}, unique={unique}\"))\n",
    "            else:\n",
    "                checks.append((\"CHK-004\",\"token_uniqueness\",\"FAIL\", f\"total={total}, unique={unique}\"))\n",
    "        else:\n",
    "            checks.append((\"CHK-004\",\"token_uniqueness\",\"FAIL\",\"'token' column not found\"))\n",
    "\n",
    "        # c) Status counts\n",
    "        if 'status' in df.columns:\n",
    "            counts = df['status'].value_counts().to_dict()\n",
    "            checks.append((\"CHK-005\",\"status_counts\",\"INFO\", json.dumps(counts)))\n",
    "        else:\n",
    "            checks.append((\"CHK-005\",\"status_counts\",\"INFO\",\"status column missing\"))\n",
    "    except Exception as e:\n",
    "        checks.append((\"CHK-ERROR\",\"token_file_parse_error\",\"FAIL\", str(e)))\n",
    "\n",
    "print (\"Validation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b468cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple PCI checks completed. Summary:\n",
      "- CHK-001 | tokenized_file_present | PASS | C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\\outputs\\tokenized_payments.csv\n",
      "- CHK-002 | baseline_present | PASS | C:\\Project\\SafePay\\01_Case\\B_PCI_Controls_and_Audit\n",
      "- CHK-003 | pan_leak_check | PASS | No PAN-like sequences found\n",
      "- CHK-004 | token_uniqueness | PASS | total=1200, unique=1200\n",
      "- CHK-005 | status_counts | INFO | {\"failed\": 423, \"success\": 398, \"declined\": 379}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check_id</th>\n",
       "      <th>check_name</th>\n",
       "      <th>result</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHK-001</td>\n",
       "      <td>tokenized_file_present</td>\n",
       "      <td>PASS</td>\n",
       "      <td>C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHK-002</td>\n",
       "      <td>baseline_present</td>\n",
       "      <td>PASS</td>\n",
       "      <td>C:\\Project\\SafePay\\01_Case\\B_PCI_Controls_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHK-003</td>\n",
       "      <td>pan_leak_check</td>\n",
       "      <td>PASS</td>\n",
       "      <td>No PAN-like sequences found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHK-004</td>\n",
       "      <td>token_uniqueness</td>\n",
       "      <td>PASS</td>\n",
       "      <td>total=1200, unique=1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHK-005</td>\n",
       "      <td>status_counts</td>\n",
       "      <td>INFO</td>\n",
       "      <td>{\"failed\": 423, \"success\": 398, \"declined\": 379}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  check_id              check_name result  \\\n",
       "0  CHK-001  tokenized_file_present   PASS   \n",
       "1  CHK-002        baseline_present   PASS   \n",
       "2  CHK-003          pan_leak_check   PASS   \n",
       "3  CHK-004        token_uniqueness   PASS   \n",
       "4  CHK-005           status_counts   INFO   \n",
       "\n",
       "                                             details  \n",
       "0  C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\\...  \n",
       "1  C:\\Project\\SafePay\\01_Case\\B_PCI_Controls_and_...  \n",
       "2                        No PAN-like sequences found  \n",
       "3                            total=1200, unique=1200  \n",
       "4   {\"failed\": 423, \"success\": 398, \"declined\": 379}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Save results\n",
    "evidence_csv = output_path / \"pci_evidence.csv\"\n",
    "with open(evidence_csv, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['check_id','check_name','result','details'])\n",
    "    for r in checks:\n",
    "        w.writerow(r)\n",
    "\n",
    "detail_json = output_path / \"pci_checks_detail.json\"\n",
    "detail = {\"run_ts\": datetime.datetime.now().isoformat()+\"Z\", \"checks\": []}\n",
    "for cid, name, res, details in checks:\n",
    "    detail[\"checks\"].append({\"id\": cid, \"name\": name, \"result\": res, \"details\": details})\n",
    "detail_json.write_text(json.dumps(detail, indent=2))\n",
    "\n",
    "# 4) Show results here\n",
    "print(\"Simple PCI checks completed. Summary:\")\n",
    "for cid, name, res, details in checks:\n",
    "    print(f\"- {cid} | {name} | {res} | {details}\")\n",
    "\n",
    "pd.read_csv(evidence_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
