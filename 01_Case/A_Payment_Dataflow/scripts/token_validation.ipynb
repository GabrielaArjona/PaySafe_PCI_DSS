{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4194188",
   "metadata": {},
   "source": [
    "# A) Payment Dataflow\n",
    "\n",
    "Goals:\n",
    "\n",
    "Verify that tokenized_payments.csv exists.\n",
    "\n",
    "Look for Primary Account Number-like sequences (13â€“19 digits) in all columns.\n",
    "\n",
    "Check for token uniqueness.\n",
    "\n",
    "Display counts by status.\n",
    "\n",
    "Write outputs/validation_report.csv with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5712a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re, datetime, csv, hashlib, json\n",
    "import pandas as pd\n",
    "BASE = Path('..').resolve()\n",
    "print(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7743d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation report written to C:\\Project\\SafePay\\01_Case\\A_Payment_Dataflow\\outputs\\validation_report.csv\n",
      "            check  result                                          details\n",
      "token_file_exists    True                                        rows=1200\n",
      "pan_leak_detected    True    No PAN-like sequences found in tokenized file\n",
      " token_uniqueness    True                          total=1200, unique=1200\n",
      "    status_counts    True {\"failed\": 423, \"success\": 398, \"declined\": 379}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = BASE / 'outputs'\n",
    "reports = []\n",
    "\n",
    "# Load tokenized outputs\n",
    "tok_file = out_dir / 'tokenized_payments.csv'\n",
    "pan_pattern = re.compile(r'\\b\\d{13,19}\\b')\n",
    "if tok_file.exists():\n",
    "    tok = pd.read_csv(tok_file)\n",
    "    reports.append({'check':'token_file_exists','result':True,'details':f'rows={len(tok)}'})\n",
    "    # 1) Check PAN-like sequences\n",
    "    def contains_pan_like(v):\n",
    "        try:\n",
    "            return bool(pan_pattern.search(str(v)))\n",
    "        except:\n",
    "            return False\n",
    "    pan_found_cols = [col for col in tok.columns if tok[col].astype(str).apply(contains_pan_like).any()]\n",
    "    if pan_found_cols:\n",
    "        reports.append({'check':'pan_leak_detected','result':False,'details':f'PAN-like string found in columns: {pan_found_cols}'})\n",
    "    else:\n",
    "        reports.append({'check':'pan_leak_detected','result':True,'details':'No PAN-like sequences found in tokenized file'})\n",
    "    # 2) token uniqueness\n",
    "    total = len(tok)\n",
    "    unique_tokens = tok['token'].nunique() if 'token' in tok.columns else 0\n",
    "    reports.append({'check':'token_uniqueness','result': unique_tokens==total,'details':f'total={total}, unique={unique_tokens}'})\n",
    "    # 3) basic counts by status...if present\n",
    "    if 'status' in tok.columns:\n",
    "        counts = tok['status'].value_counts().to_dict()\n",
    "        reports.append({'check':'status_counts','result':True,'details':json.dumps(counts)})\n",
    "else:\n",
    "    reports.append({'check':'token_file_exists','result':False,'details':'tokenized_payments.csv not found'})\n",
    "\n",
    "# validation report\n",
    "vr = pd.DataFrame(reports)\n",
    "out_file = out_dir / 'validation_report.csv'\n",
    "vr.to_csv(out_file, index=False)\n",
    "print('Validation report written to', out_file)\n",
    "print(vr.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
